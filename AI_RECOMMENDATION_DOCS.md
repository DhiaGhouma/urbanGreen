# ğŸ¤– SystÃ¨me de Recommandation AI - Documentation

## ğŸ“‹ Vue d'ensemble

Ce systÃ¨me utilise une approche **RAG (Retrieval-Augmented Generation)** pour recommander le meilleur espace vert Ã  un utilisateur lors de la crÃ©ation d'une participation.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Laravel   â”‚ â† Interface utilisateur
â”‚ Controller  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AIRecommend â”‚ â† Service PHP
â”‚   Service   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Python    â”‚ â† Script RAG
â”‚ai_recommenderâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â–º ğŸ” Embeddings (sentence-transformers)
       â”‚   â””â”€â–º PrÃ©-filtrage rapide (< 2 secondes)
       â”‚
       â””â”€â–º ğŸ¤– Ollama (llama3.1)
           â””â”€â–º SÃ©lection intelligente avec explication (< 10 secondes)
```

## ğŸš€ FonctionnalitÃ©s

### 1. **Gestion des PrÃ©fÃ©rences Utilisateur**

-   Interface web pour dÃ©finir ses prÃ©fÃ©rences
-   Route: `/preferences`
-   Stockage JSON dans la table `users`

### 2. **Recommandation AI**

-   Bouton "SuggÃ©rer avec l'IA" dans le formulaire de participation
-   Appel AJAX vers `/participations/suggest/ai`
-   Affichage du rÃ©sultat avec explication

### 3. **Fallback Automatique**

-   Si Ollama est indisponible â†’ Utilise uniquement les embeddings
-   Si Python Ã©choue â†’ Utilise matching par mots-clÃ©s
-   **ZÃ©ro interruption de service**

## ğŸ“ Fichiers CrÃ©Ã©s

### Backend PHP (Laravel)

```
app/
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ OllamaService.php          â†’ Interface avec Ollama API
â”‚   â””â”€â”€ AIRecommender.php          â†’ Orchestration de la recommandation
â””â”€â”€ Http/Controllers/
    â””â”€â”€ UserPreferenceController.php â†’ Gestion des prÃ©fÃ©rences
```

### Backend Python

```
ai_recommender.py                   â†’ Script RAG principal
test_recommender.py                 â†’ Script de test
```

### Frontend (Blade)

```
resources/views/users/
â””â”€â”€ preferences.blade.php           â†’ Page de configuration des prÃ©fÃ©rences
```

### Database

```
database/seeders/
â”œâ”€â”€ UserPreferencesSeeder.php       â†’ Ajoute des prÃ©fÃ©rences par dÃ©faut
â””â”€â”€ GreenSpaceActivitiesSeeder.php  â†’ Ajoute des activitÃ©s aux espaces verts
```

## ğŸ”§ Configuration

### Variables d'environnement (.env)

```env
PYTHON_BIN='C:\Users\moeta\OneDrive\Desktop\5eme-Projects\urbanGreen\.venv\Scripts\python.exe'
OLLAMA_BIN='C:\Users\moeta\AppData\Local\Programs\Ollama\ollama.exe'
OLLAMA_MODEL=llama3.1
```

### Routes (routes/web.php)

```php
// PrÃ©fÃ©rences utilisateur
Route::get('/preferences', [UserPreferenceController::class, 'edit'])->name('preferences.edit');
Route::put('/preferences', [UserPreferenceController::class, 'update'])->name('preferences.update');

// Recommandation AI
Route::get('participations/suggest/ai', [ParticipationController::class, 'suggest'])
    ->name('participations.suggest')
    ->middleware('auth');
```

## ğŸ¯ Utilisation

### Pour l'utilisateur

1. **Configurer ses prÃ©fÃ©rences**

    - Menu utilisateur â†’ "Mes PrÃ©fÃ©rences IA"
    - SÃ©lectionner intÃ©rÃªts, activitÃ©s, disponibilitÃ©, niveau d'expÃ©rience
    - Enregistrer

2. **CrÃ©er une participation**
    - Menu â†’ Participations â†’ Nouvelle Participation
    - Cliquer sur "SuggÃ©rer avec l'IA"
    - L'espace vert recommandÃ© est automatiquement sÃ©lectionnÃ©
    - Une explication est affichÃ©e

### Pour le dÃ©veloppeur

#### Tester le script Python

```bash
cd C:\Users\moeta\OneDrive\Desktop\5eme-Projects\urbanGreen
.\.venv\Scripts\python.exe test_recommender.py
```

#### Appeler le service depuis Laravel

```php
use App\Services\AIRecommender;

public function suggest(Request $request, AIRecommender $recommender)
{
    $user = auth()->user();
    $greenspaces = GreenSpace::all();

    $result = $recommender->recommend($user, $greenspaces);

    return response()->json($result);
}
```

## âš¡ Performance

### Temps de rÃ©ponse typiques

| ScÃ©nario                    | Temps                                  |
| --------------------------- | -------------------------------------- |
| Embeddings seuls (fallback) | **1-3 secondes** âš¡                    |
| RAG complet (Ollama actif)  | **5-15 secondes** ğŸš€                   |
| Ollama premiÃ¨re utilisation | 15-30 secondes (tÃ©lÃ©chargement modÃ¨le) |

### Optimisations appliquÃ©es

1. **PrÃ©-filtrage avec embeddings** : RÃ©duit drastiquement la quantitÃ© de donnÃ©es envoyÃ©es Ã  Ollama
2. **Top-K = 2** : Seulement 2 candidats envoyÃ©s Ã  Ollama au lieu de tous
3. **Temperature = 0.3** : RÃ©ponses plus consistantes et rapides
4. **Timeout adaptatif** : 45s pour Ollama, fallback automatique aprÃ¨s
5. **ModÃ¨le d'embedding lÃ©ger** : `paraphrase-multilingual-MiniLM-L12-v2` (471 MB)

## ğŸ› ï¸ Maintenance

### DÃ©marrer Ollama manuellement

```powershell
Start-Process -FilePath 'C:\Users\moeta\AppData\Local\Programs\Ollama\ollama.exe' -ArgumentList 'serve' -WindowStyle Hidden
```

### VÃ©rifier les logs

```bash
# Logs Laravel
tail -f storage/logs/laravel.log

# VÃ©rifier si Ollama est actif
curl http://localhost:11434/api/tags
```

### Ajouter un nouveau modÃ¨le Ollama

```bash
ollama pull llama3.2
```

Puis modifier `.env` :

```env
OLLAMA_MODEL=llama3.2
```

## ğŸ§ª Tests

### Test unitaire Python

```bash
.\.venv\Scripts\python.exe test_recommender.py
```

### Test d'intÃ©gration Laravel

```bash
php artisan test --filter=AIRecommenderTest
```

## ğŸ› DÃ©pannage

### ProblÃ¨me : "Ollama indisponible"

**Solution 1** : DÃ©marrer Ollama

```powershell
& 'C:\Users\moeta\AppData\Local\Programs\Ollama\ollama.exe' serve
```

**Solution 2** : Le systÃ¨me utilise automatiquement le fallback (embeddings seuls)

### ProblÃ¨me : "Python script timeout"

**Cause** : Le modÃ¨le d'embedding se tÃ©lÃ©charge la premiÃ¨re fois (471 MB)

**Solution** : Attendre la premiÃ¨re exÃ©cution (9-10 minutes), puis c'est instantanÃ©

### ProblÃ¨me : "Recommandation toujours la mÃªme"

**Cause** : PrÃ©fÃ©rences utilisateur vides ou identiques

**Solution** : Aller dans "Mes PrÃ©fÃ©rences IA" et personnaliser

## ğŸ“Š Structure des DonnÃ©es

### User Preferences (JSON)

```json
{
    "interests": ["jardinage", "nature", "fleurs"],
    "preferred_activities": ["plantation", "entretien", "arrosage"],
    "availability": "weekends",
    "experience_level": "dÃ©butant"
}
```

### GreenSpace Activities (JSON)

```json
["plantation", "arrosage", "entretien", "nettoyage", "Ã©vÃ©nements"]
```

### RÃ©sultat de Recommandation

```json
{
    "best_match_id": 2,
    "score": 0.85,
    "reason": "Le Jardin Botanique correspond parfaitement Ã  vos intÃ©rÃªts en jardinage et nature. Les ateliers de plantation proposÃ©s sont idÃ©aux pour votre niveau dÃ©butant.",
    "engine": "ollama+embeddings",
    "computation_time": "8.5s"
}
```

## ğŸ” SÃ©curitÃ©

-   âœ… Authentification requise pour la recommandation
-   âœ… Validation des entrÃ©es utilisateur
-   âœ… Timeout sur les appels externes (Ollama)
-   âœ… Fallback automatique en cas d'erreur
-   âœ… Logs dÃ©taillÃ©s pour audit

## ğŸ“ˆ AmÃ©liorations Futures

1. **Cache Redis** : Mettre en cache les embeddings des greenspaces
2. **Historique** : Apprendre des choix prÃ©cÃ©dents de l'utilisateur
3. **A/B Testing** : Comparer diffÃ©rentes stratÃ©gies de recommandation
4. **Multi-critÃ¨res** : Ajouter distance gÃ©ographique, disponibilitÃ© horaire
5. **API REST** : Exposer le service en API pour applications mobiles

## ğŸ“ CrÃ©dits

-   **ModÃ¨le d'embedding** : sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
-   **LLM** : Meta Llama 3.1 (via Ollama)
-   **Framework RAG** : Langchain
-   **Framework Web** : Laravel 11

---

**DÃ©veloppÃ© avec â¤ï¸ pour UrbanGreen**

_Version 1.0 - Octobre 2025_
